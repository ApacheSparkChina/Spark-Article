原文链接：
https://databricks.com/blog/2019/06/26/scaling-genomic-workflows-with-spark-sql-bgen-and-vcf-readers.html

编译:
诚历，阿里巴巴计算平台事业部 EMR 技术专家，Apache Sentry PMC，Apache Commons Committer，目前从事开源大数据存储和优化方面的工作。

摘要
我们相信Spark SQL已经成为处理各种不同风格的大量数据集的标准，代表了通向简单、可扩展的基因组工作流程的最直接途径。 
Spark SQL用于以分布式方式来对（ETL）大数据进行提取，转换和加载。 
ETL是生物信息学所涉及工作的90％，从提取突变，用外部数据源注释，到为下游统计和机器学习分析做准备。 
Spark SQL包含Python或R等语言的高级API，这些API易于学习，并且比传统的生物信息学方法更容易阅读和维护代码。
在这篇文章中，我们将介绍在基因组数据和Spark SQL之间提供强大及灵活连接的数据Reader和Writer。

编译原文链接：
https://yq.aliyun.com/articles/708921

钉钉群号：23109202
团队群号：HPRX8117
微信公众号：Apache Spark技术交流社区
